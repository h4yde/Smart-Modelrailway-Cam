{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Retrain EfficientDet-Lite0 Model for the \"Modelrailway-Cam\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr3q-gvm3cI8"
      },
      "source": [
        "In this jupyter-notebook, we'll retrain an EfficientDet-Lite object detection model (derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html)) using the [TensorFlow Lite Model Maker library](https://www.tensorflow.org/lite/guide/model_maker), and then compile it to run on the [Coral Edge TPU](https://www.coral.ai/products/). All in about 10 minutes on a GPU. Please change runtime type (Laufzeittyp) to \"GPU\" in the menue.\n",
        "\n",
        "This notebook retrains the model using images of a modelrailway showing locomotives and waggons. It is an adapted version of the original notebook: [Train a salad detector with TFLite Model Maker - Colaboratory (google.com)](https://colab.research.google.com/github/googlecodelabs/odml-pathways/blob/main/object-detection/codelab2/python/Train_a_salad_detector_with_TFLite_Model_Maker.ipynb)\n",
        "\n",
        "Author: Detlef Heinze   Version: 1.1 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caution. \n",
        "Before running any cell of this jupyter notebook please\n",
        "- press CTRL-SHIFT-P: selecet \"Connect Runtime\" (Laufzeit starten)\n",
        "- press CTRL-SHIF-P:  select \"Use fallback runtime\" (\"Fallback-Laufzeit)\n"
      ],
      "metadata": {
        "id": "pdcy9EJ6Fsny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# -*- coding: utf-8 -*-"
      ],
      "metadata": {
        "id": "IgYinplOpkKK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use your google drive for this notebook. Follow messages on scren.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "s80ycacXldoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5d941b-b02f-4717-ea78-96dffcf0ffa2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzoNZRp4sVxK"
      },
      "source": [
        "The training data used must be present in the path /content/drive/MyDrive/TrainData\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvAObmTqglq"
      },
      "source": [
        "## Import the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qhl8lqVamEty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052f956f-28b4-4761-bd45-179d3ec9b7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 65.4 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudio2 amd64 19.6.0-1build1 [65.4 kB]\n",
            "Fetched 65.4 kB in 0s (485 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 122400 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1build1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1build1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.3/577.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.10.1 requires matplotlib>=3.5.0, but you'll have matplotlib 3.4.3 which is incompatible.\n",
            "mizani 0.8.1 requires matplotlib>=3.5.0, but you'll have matplotlib 3.4.3 which is incompatible.\n",
            "scann 1.2.6 requires tensorflow~=2.8.0, but you'll have tensorflow 2.12.0 which is incompatible.\n",
            "tensorflow-model-optimization 0.7.4 requires numpy~=1.23, but you'll have numpy 1.22.4 which is incompatible.\n",
            "tensorflowjs 3.18.0 requires packaging~=20.9, but you'll have packaging 23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python-headless==4.1.2.30 (from versions: 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.14.51, 3.4.14.53, 3.4.15.55, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.2.52, 4.5.2.54, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python-headless==4.1.2.30\u001b[0m\u001b[31m\n",
            "\u001b[0mFound existing installation: tensorflow 2.12.0\n",
            "Uninstalling tensorflow-2.12.0:\n",
            "  Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflowjs 3.18.0 requires packaging~=20.9, but you have packaging 23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q --use-deprecated=legacy-resolver tflite-model-maker\n",
        "!pip install -q pycocotools\n",
        "!pip install -q opencv-python-headless==4.1.2.30\n",
        "!pip uninstall -y tensorflow && pip install -q tensorflow==2.8.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XtxiUeZEiXpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d50c9bb-c3e6-42a6-f201-6eb4f7e98226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XM-oIfhgQ7"
      },
      "source": [
        "## Load the training data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VoZ_Rud2V3"
      },
      "source": [
        "### Load the training data set by using training.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRd13bfetO7B"
      },
      "source": [
        "\n",
        "\n",
        "Model Maker requires that we load our dataset using the [`DataLoader`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/DataLoader) API. So in this case, we'll load it from a CSV file that defines the images for training, images for validation, and images for testing. At the start change directory  to the Data directory.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "04ObtdneqvP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a875f712-57e8-4561-b49d-3b8e7b70ed99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TrainData\n"
          ]
        }
      ],
      "source": [
        "#Load the CSV file from your Google Drive.\n",
        "%cd drive/MyDrive/TrainData\n",
        "train_data, validation_data, test_data = object_detector.DataLoader.from_csv('training.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8clx0KPutCM"
      },
      "source": [
        "## Select the model spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn61LJ9QbOPi"
      },
      "source": [
        "Model Maker supports the EfficientDet-Lite family of object detection models that are compatible with the Edge TPU. (EfficientDet-Lite is derived from [EfficientDet](https://ai.googleblog.com/2020/04/efficientdet-towards-scalable-and.html), which offers state-of-the-art accuracy in a small model size). There are several model sizes you can choose from:\n",
        "\n",
        "|| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|-|--------------------|-----------|---------------|----------------------|\n",
        "|| EfficientDet-Lite0 | 5.7       | 37.4            | 30.4%               |\n",
        "|| EfficientDet-Lite1 | 7.6       | 56.3            | 34.3%               |\n",
        "|| EfficientDet-Lite2 | 10.2      | 104.6           | 36.0%               |\n",
        "|| EfficientDet-Lite3 | 14.4      | 107.6           | 39.4%               |\n",
        "| <td colspan=4><br><i>* File size of the compiled Edge TPU models. <br/>** Latency measured on a desktop CPU with a Coral USB Accelerator. <br/>*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.</i></td> |\n",
        "\n",
        "Beware that the Lite2 and Lite3 models do not fit onto the Edge TPU's onboard memory, so you'll see even greater latency when using those, due to the cost of fetching data from the host system memory. Maybe this extra latency is okay for your application, but if it's not and you require the precision of the larger models, then you can [pipeline the model across multiple Edge TPUs](https://coral.ai/docs/edgetpu/pipeline/) (more about this when we compile the model below).\n",
        "\n",
        "For the modelrailway-cam, we'll use Lite0:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SM9gePHw9Jv1"
      },
      "outputs": [],
      "source": [
        "spec = object_detector.EfficientDetLite0Spec()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qjq2UEHCLUi"
      },
      "source": [
        "## Create and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uZkLR6N6gDR"
      },
      "source": [
        "Now we need to create our model according to the model spec, load our dataset into the model, specify training parameters, and begin training. \n",
        "\n",
        "Using Model Maker, we accomplished all of that with [`create()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/create):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kwlYdTcg63xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b3d2e0-42d5-4d9f-dd7a-b9b9d903d342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "46/46 [==============================] - 60s 347ms/step - det_loss: 1.4468 - cls_loss: 0.9080 - box_loss: 0.0108 - reg_l2_loss: 0.0630 - loss: 1.5099 - learning_rate: 0.0090 - gradient_norm: 2.5357 - val_det_loss: 0.8321 - val_cls_loss: 0.5661 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0630 - val_loss: 0.8952\n",
            "Epoch 2/40\n",
            "46/46 [==============================] - 13s 289ms/step - det_loss: 0.7435 - cls_loss: 0.4230 - box_loss: 0.0064 - reg_l2_loss: 0.0631 - loss: 0.8066 - learning_rate: 0.0100 - gradient_norm: 3.5050 - val_det_loss: 0.7885 - val_cls_loss: 0.2546 - val_box_loss: 0.0107 - val_reg_l2_loss: 0.0631 - val_loss: 0.8517\n",
            "Epoch 3/40\n",
            "46/46 [==============================] - 15s 330ms/step - det_loss: 0.4893 - cls_loss: 0.2684 - box_loss: 0.0044 - reg_l2_loss: 0.0632 - loss: 0.5525 - learning_rate: 0.0099 - gradient_norm: 3.2602 - val_det_loss: 0.3874 - val_cls_loss: 0.2460 - val_box_loss: 0.0028 - val_reg_l2_loss: 0.0632 - val_loss: 0.4506\n",
            "Epoch 4/40\n",
            "46/46 [==============================] - 15s 315ms/step - det_loss: 0.4243 - cls_loss: 0.2428 - box_loss: 0.0036 - reg_l2_loss: 0.0632 - loss: 0.4875 - learning_rate: 0.0098 - gradient_norm: 2.8352 - val_det_loss: 0.6185 - val_cls_loss: 0.4408 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0633 - val_loss: 0.6817\n",
            "Epoch 5/40\n",
            "46/46 [==============================] - 21s 457ms/step - det_loss: 0.3857 - cls_loss: 0.2215 - box_loss: 0.0033 - reg_l2_loss: 0.0633 - loss: 0.4490 - learning_rate: 0.0097 - gradient_norm: 2.8560 - val_det_loss: 0.2726 - val_cls_loss: 0.1380 - val_box_loss: 0.0027 - val_reg_l2_loss: 0.0633 - val_loss: 0.3359\n",
            "Epoch 6/40\n",
            "46/46 [==============================] - 15s 319ms/step - det_loss: 0.3332 - cls_loss: 0.1869 - box_loss: 0.0029 - reg_l2_loss: 0.0633 - loss: 0.3965 - learning_rate: 0.0095 - gradient_norm: 2.4058 - val_det_loss: 0.2232 - val_cls_loss: 0.1240 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0633 - val_loss: 0.2865\n",
            "Epoch 7/40\n",
            "46/46 [==============================] - 13s 274ms/step - det_loss: 0.3235 - cls_loss: 0.1930 - box_loss: 0.0026 - reg_l2_loss: 0.0633 - loss: 0.3869 - learning_rate: 0.0093 - gradient_norm: 2.3913 - val_det_loss: 0.2044 - val_cls_loss: 0.1341 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0633 - val_loss: 0.2677\n",
            "Epoch 8/40\n",
            "46/46 [==============================] - 14s 305ms/step - det_loss: 0.3026 - cls_loss: 0.1898 - box_loss: 0.0023 - reg_l2_loss: 0.0633 - loss: 0.3660 - learning_rate: 0.0091 - gradient_norm: 2.6289 - val_det_loss: 0.2294 - val_cls_loss: 0.1277 - val_box_loss: 0.0020 - val_reg_l2_loss: 0.0634 - val_loss: 0.2928\n",
            "Epoch 9/40\n",
            "46/46 [==============================] - 15s 326ms/step - det_loss: 0.2921 - cls_loss: 0.1751 - box_loss: 0.0023 - reg_l2_loss: 0.0634 - loss: 0.3554 - learning_rate: 0.0089 - gradient_norm: 2.3272 - val_det_loss: 0.2139 - val_cls_loss: 0.1450 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0634 - val_loss: 0.2773\n",
            "Epoch 10/40\n",
            "46/46 [==============================] - 17s 375ms/step - det_loss: 0.2511 - cls_loss: 0.1514 - box_loss: 0.0020 - reg_l2_loss: 0.0634 - loss: 0.3144 - learning_rate: 0.0086 - gradient_norm: 2.0813 - val_det_loss: 0.1681 - val_cls_loss: 0.0980 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0634 - val_loss: 0.2315\n",
            "Epoch 11/40\n",
            "46/46 [==============================] - 14s 302ms/step - det_loss: 0.2522 - cls_loss: 0.1527 - box_loss: 0.0020 - reg_l2_loss: 0.0634 - loss: 0.3156 - learning_rate: 0.0083 - gradient_norm: 2.2508 - val_det_loss: 0.2650 - val_cls_loss: 0.1898 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0634 - val_loss: 0.3284\n",
            "Epoch 12/40\n",
            "46/46 [==============================] - 13s 280ms/step - det_loss: 0.2488 - cls_loss: 0.1454 - box_loss: 0.0021 - reg_l2_loss: 0.0634 - loss: 0.3122 - learning_rate: 0.0080 - gradient_norm: 2.0982 - val_det_loss: 0.1602 - val_cls_loss: 0.1053 - val_box_loss: 0.0011 - val_reg_l2_loss: 0.0634 - val_loss: 0.2236\n",
            "Epoch 13/40\n",
            "46/46 [==============================] - 14s 315ms/step - det_loss: 0.2340 - cls_loss: 0.1406 - box_loss: 0.0019 - reg_l2_loss: 0.0634 - loss: 0.2974 - learning_rate: 0.0077 - gradient_norm: 2.0962 - val_det_loss: 0.1381 - val_cls_loss: 0.0947 - val_box_loss: 8.6837e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2015\n",
            "Epoch 14/40\n",
            "46/46 [==============================] - 15s 327ms/step - det_loss: 0.2350 - cls_loss: 0.1382 - box_loss: 0.0019 - reg_l2_loss: 0.0634 - loss: 0.2984 - learning_rate: 0.0073 - gradient_norm: 2.0208 - val_det_loss: 0.1482 - val_cls_loss: 0.1036 - val_box_loss: 8.9242e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2116\n",
            "Epoch 15/40\n",
            "46/46 [==============================] - 17s 373ms/step - det_loss: 0.2284 - cls_loss: 0.1411 - box_loss: 0.0017 - reg_l2_loss: 0.0634 - loss: 0.2918 - learning_rate: 0.0070 - gradient_norm: 2.1368 - val_det_loss: 0.1977 - val_cls_loss: 0.1491 - val_box_loss: 9.7241e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2611\n",
            "Epoch 16/40\n",
            "46/46 [==============================] - 13s 280ms/step - det_loss: 0.2520 - cls_loss: 0.1546 - box_loss: 0.0019 - reg_l2_loss: 0.0634 - loss: 0.3154 - learning_rate: 0.0066 - gradient_norm: 2.1658 - val_det_loss: 0.2751 - val_cls_loss: 0.1002 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0634 - val_loss: 0.3385\n",
            "Epoch 17/40\n",
            "46/46 [==============================] - 14s 303ms/step - det_loss: 0.2154 - cls_loss: 0.1328 - box_loss: 0.0017 - reg_l2_loss: 0.0634 - loss: 0.2788 - learning_rate: 0.0062 - gradient_norm: 2.0598 - val_det_loss: 0.1906 - val_cls_loss: 0.1279 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0634 - val_loss: 0.2540\n",
            "Epoch 18/40\n",
            "46/46 [==============================] - 14s 312ms/step - det_loss: 0.2002 - cls_loss: 0.1181 - box_loss: 0.0016 - reg_l2_loss: 0.0634 - loss: 0.2636 - learning_rate: 0.0058 - gradient_norm: 1.7011 - val_det_loss: 0.1379 - val_cls_loss: 0.0833 - val_box_loss: 0.0011 - val_reg_l2_loss: 0.0634 - val_loss: 0.2013\n",
            "Epoch 19/40\n",
            "46/46 [==============================] - 15s 333ms/step - det_loss: 0.2075 - cls_loss: 0.1245 - box_loss: 0.0017 - reg_l2_loss: 0.0634 - loss: 0.2709 - learning_rate: 0.0054 - gradient_norm: 1.9516 - val_det_loss: 0.1565 - val_cls_loss: 0.0970 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0634 - val_loss: 0.2199\n",
            "Epoch 20/40\n",
            "46/46 [==============================] - 15s 336ms/step - det_loss: 0.1778 - cls_loss: 0.1187 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2412 - learning_rate: 0.0050 - gradient_norm: 1.7835 - val_det_loss: 0.1552 - val_cls_loss: 0.1166 - val_box_loss: 7.7315e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2186\n",
            "Epoch 21/40\n",
            "46/46 [==============================] - 13s 278ms/step - det_loss: 0.1796 - cls_loss: 0.1173 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2430 - learning_rate: 0.0046 - gradient_norm: 1.8191 - val_det_loss: 0.1330 - val_cls_loss: 0.0933 - val_box_loss: 7.9463e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1964\n",
            "Epoch 22/40\n",
            "46/46 [==============================] - 14s 311ms/step - det_loss: 0.1888 - cls_loss: 0.1166 - box_loss: 0.0014 - reg_l2_loss: 0.0634 - loss: 0.2522 - learning_rate: 0.0042 - gradient_norm: 1.7713 - val_det_loss: 0.1400 - val_cls_loss: 0.0900 - val_box_loss: 9.9993e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2034\n",
            "Epoch 23/40\n",
            "46/46 [==============================] - 15s 338ms/step - det_loss: 0.1782 - cls_loss: 0.1128 - box_loss: 0.0013 - reg_l2_loss: 0.0634 - loss: 0.2416 - learning_rate: 0.0038 - gradient_norm: 1.9187 - val_det_loss: 0.1251 - val_cls_loss: 0.0877 - val_box_loss: 7.4718e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1884\n",
            "Epoch 24/40\n",
            "46/46 [==============================] - 14s 304ms/step - det_loss: 0.1752 - cls_loss: 0.1159 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2386 - learning_rate: 0.0034 - gradient_norm: 1.8009 - val_det_loss: 0.1079 - val_cls_loss: 0.0736 - val_box_loss: 6.8518e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1713\n",
            "Epoch 25/40\n",
            "46/46 [==============================] - 15s 331ms/step - det_loss: 0.1753 - cls_loss: 0.1129 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2387 - learning_rate: 0.0030 - gradient_norm: 1.8571 - val_det_loss: 0.1060 - val_cls_loss: 0.0753 - val_box_loss: 6.1326e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1694\n",
            "Epoch 26/40\n",
            "46/46 [==============================] - 14s 296ms/step - det_loss: 0.1656 - cls_loss: 0.1069 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2290 - learning_rate: 0.0027 - gradient_norm: 1.7833 - val_det_loss: 0.1292 - val_cls_loss: 0.0867 - val_box_loss: 8.5111e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1926\n",
            "Epoch 27/40\n",
            "46/46 [==============================] - 14s 314ms/step - det_loss: 0.1739 - cls_loss: 0.1165 - box_loss: 0.0011 - reg_l2_loss: 0.0634 - loss: 0.2373 - learning_rate: 0.0023 - gradient_norm: 1.8079 - val_det_loss: 0.1143 - val_cls_loss: 0.0806 - val_box_loss: 6.7341e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1776\n",
            "Epoch 28/40\n",
            "46/46 [==============================] - 14s 312ms/step - det_loss: 0.1623 - cls_loss: 0.1032 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2257 - learning_rate: 0.0020 - gradient_norm: 1.6113 - val_det_loss: 0.0998 - val_cls_loss: 0.0724 - val_box_loss: 5.4769e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1632\n",
            "Epoch 29/40\n",
            "46/46 [==============================] - 12s 269ms/step - det_loss: 0.1534 - cls_loss: 0.1003 - box_loss: 0.0011 - reg_l2_loss: 0.0634 - loss: 0.2167 - learning_rate: 0.0017 - gradient_norm: 1.5985 - val_det_loss: 0.0962 - val_cls_loss: 0.0720 - val_box_loss: 4.8480e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1596\n",
            "Epoch 30/40\n",
            "46/46 [==============================] - 16s 344ms/step - det_loss: 0.1624 - cls_loss: 0.1034 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2258 - learning_rate: 0.0014 - gradient_norm: 1.5670 - val_det_loss: 0.0938 - val_cls_loss: 0.0702 - val_box_loss: 4.7178e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1572\n",
            "Epoch 31/40\n",
            "46/46 [==============================] - 14s 312ms/step - det_loss: 0.1550 - cls_loss: 0.1061 - box_loss: 9.7875e-04 - reg_l2_loss: 0.0634 - loss: 0.2184 - learning_rate: 0.0011 - gradient_norm: 1.7896 - val_det_loss: 0.1051 - val_cls_loss: 0.0718 - val_box_loss: 6.6523e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1684\n",
            "Epoch 32/40\n",
            "46/46 [==============================] - 14s 313ms/step - det_loss: 0.1534 - cls_loss: 0.1015 - box_loss: 0.0010 - reg_l2_loss: 0.0634 - loss: 0.2168 - learning_rate: 8.8634e-04 - gradient_norm: 1.5830 - val_det_loss: 0.0974 - val_cls_loss: 0.0704 - val_box_loss: 5.3887e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1607\n",
            "Epoch 33/40\n",
            "46/46 [==============================] - 13s 276ms/step - det_loss: 0.1536 - cls_loss: 0.1025 - box_loss: 0.0010 - reg_l2_loss: 0.0634 - loss: 0.2170 - learning_rate: 6.7118e-04 - gradient_norm: 1.5831 - val_det_loss: 0.0957 - val_cls_loss: 0.0693 - val_box_loss: 5.2708e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1591\n",
            "Epoch 34/40\n",
            "46/46 [==============================] - 14s 311ms/step - det_loss: 0.1472 - cls_loss: 0.1009 - box_loss: 9.2535e-04 - reg_l2_loss: 0.0634 - loss: 0.2105 - learning_rate: 4.8410e-04 - gradient_norm: 1.5643 - val_det_loss: 0.0987 - val_cls_loss: 0.0716 - val_box_loss: 5.4179e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1621\n",
            "Epoch 35/40\n",
            "46/46 [==============================] - 16s 353ms/step - det_loss: 0.1538 - cls_loss: 0.1006 - box_loss: 0.0011 - reg_l2_loss: 0.0634 - loss: 0.2172 - learning_rate: 3.2630e-04 - gradient_norm: 1.6350 - val_det_loss: 0.0968 - val_cls_loss: 0.0713 - val_box_loss: 5.0923e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1602\n",
            "Epoch 36/40\n",
            "46/46 [==============================] - 14s 307ms/step - det_loss: 0.1642 - cls_loss: 0.1078 - box_loss: 0.0011 - reg_l2_loss: 0.0634 - loss: 0.2276 - learning_rate: 1.9881e-04 - gradient_norm: 1.7741 - val_det_loss: 0.0967 - val_cls_loss: 0.0697 - val_box_loss: 5.4042e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1601\n",
            "Epoch 37/40\n",
            "46/46 [==============================] - 13s 289ms/step - det_loss: 0.1506 - cls_loss: 0.1018 - box_loss: 9.7558e-04 - reg_l2_loss: 0.0634 - loss: 0.2140 - learning_rate: 1.0246e-04 - gradient_norm: 1.6879 - val_det_loss: 0.0969 - val_cls_loss: 0.0701 - val_box_loss: 5.3614e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1603\n",
            "Epoch 38/40\n",
            "46/46 [==============================] - 14s 303ms/step - det_loss: 0.1516 - cls_loss: 0.0996 - box_loss: 0.0010 - reg_l2_loss: 0.0634 - loss: 0.2149 - learning_rate: 3.7871e-05 - gradient_norm: 1.5408 - val_det_loss: 0.0968 - val_cls_loss: 0.0699 - val_box_loss: 5.3711e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1601\n",
            "Epoch 39/40\n",
            "46/46 [==============================] - 14s 315ms/step - det_loss: 0.1590 - cls_loss: 0.1038 - box_loss: 0.0011 - reg_l2_loss: 0.0634 - loss: 0.2223 - learning_rate: 5.4645e-06 - gradient_norm: 1.5868 - val_det_loss: 0.0966 - val_cls_loss: 0.0700 - val_box_loss: 5.3245e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1600\n",
            "Epoch 40/40\n",
            "46/46 [==============================] - 17s 366ms/step - det_loss: 0.1673 - cls_loss: 0.1076 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2306 - learning_rate: 5.4496e-06 - gradient_norm: 1.6921 - val_det_loss: 0.0965 - val_cls_loss: 0.0698 - val_box_loss: 5.3251e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.1598\n"
          ]
        }
      ],
      "source": [
        "model = object_detector.create(train_data=train_data, \n",
        "                               model_spec=spec, \n",
        "                               validation_data=validation_data, \n",
        "                               epochs=40, \n",
        "                               batch_size=8, \n",
        "                               train_whole_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n5-o3vvGfnJ"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BzCHLWJ6h7q"
      },
      "source": [
        "Now we'll use the test dataset to evaluate how well the model performs with data it has never seen before.\n",
        "\n",
        "The [`evaluate()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#evaluate) method provides output in the style of [COCO evaluation metrics](https://cocodataset.org/#detection-eval):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8xmnl6Yy7ARn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd7cc30-7a97-4fcd-86f3-43e2a589f623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r1/1 [==============================] - 10s 10s/step\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.8573558,\n",
              " 'AP50': 1.0,\n",
              " 'AP75': 1.0,\n",
              " 'APs': -1.0,\n",
              " 'APm': 0.8581418,\n",
              " 'APl': -1.0,\n",
              " 'ARmax1': 0.87115383,\n",
              " 'ARmax10': 0.88846153,\n",
              " 'ARmax100': 0.8903846,\n",
              " 'ARs': -1.0,\n",
              " 'ARm': 0.8903846,\n",
              " 'ARl': -1.0,\n",
              " 'AP_/:Dampflok': 0.840173,\n",
              " 'AP_/:Diesellok': 0.87453854}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEon9xd2BDS_"
      },
      "source": [
        "Because the default batch size for [EfficientDetLite models](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/EfficientDetSpec) is 64, this needs only 1 step to go through all  images in the test set. You can also specify the `batch_size` argument when you call [`evaluate()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#evaluate)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yB_XMpqGlLs"
      },
      "source": [
        "## Export to TensorFlow Lite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgCDMe0e6jlT"
      },
      "source": [
        "Next, we'll export the model to the TensorFlow Lite format. By default, the [`export()`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/object_detector/ObjectDetector#export) method performs [full integer post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization), which is exactly what we need for compatibility with the Edge TPU. (Model Maker uses the same dataset we gave to our model spec as a representative dataset, which is required for full-int quantization.)\n",
        "\n",
        "We just need to specify the export directory and format. By default, it exports to TF Lite, but we also want a labels file, so we declare both:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2Cu9cxX5Qu-e"
      },
      "outputs": [],
      "source": [
        "TFLITE_FILENAME = 'smrc_model.tflite'\n",
        "LABELS_FILENAME = 'railwayLabels.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rKd6qk7TbxYO"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
        "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b94hZ-exOCRB"
      },
      "source": [
        "### Evaluate the TF Lite model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQpahAIBqBPp"
      },
      "source": [
        "Exporting the model to TensorFlow Lite can affect the model accuracy, due to the reduced numerical precision from quantization and because the original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TF Lite model uses global NMS, which is faster but less accurate.\n",
        "\n",
        "Therefore you should always evaluate the exported TF Lite model and be sure it still meets your requirements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RS3Ell_lqH4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9272943f-ed03-463f-94f0-26d20e2e9354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 154s 3s/step\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AP': 0.83687276,\n",
              " 'AP50': 1.0,\n",
              " 'AP75': 1.0,\n",
              " 'APs': -1.0,\n",
              " 'APm': 0.83687276,\n",
              " 'APl': -1.0,\n",
              " 'ARmax1': 0.86153847,\n",
              " 'ARmax10': 0.86153847,\n",
              " 'ARmax100': 0.86153847,\n",
              " 'ARs': -1.0,\n",
              " 'ARm': 0.86153847,\n",
              " 'ARl': -1.0,\n",
              " 'AP_/:Dampflok': 0.82179266,\n",
              " 'AP_/:Diesellok': 0.85195285}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model.evaluate_tflite(TFLITE_FILENAME, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxgWQyYOqZha"
      },
      "source": [
        "## Compile for the Edge TPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0QLiwCj9Pw6"
      },
      "source": [
        "First we need to download the Edge TPU Compiler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Oy3QIn_YqaRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd948991-5614-4505-c60a-695aa660da9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [77.6 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,010 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Ign:10 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:10 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease [24.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,049 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,344 kB]\n",
            "Hit:17 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,699 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,578 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,197 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,240 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,408 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,216 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal/main amd64 Packages [46.8 kB]\n",
            "Fetched 18.3 MB in 3s (5,956 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 73 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 1s (13.3 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 122406 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWewhqFqeL_"
      },
      "source": [
        "Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory. \n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n",
        "\n",
        "One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n",
        "\n",
        "The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n",
        "\n",
        "| Model architecture | Minimum TPUs | Recommended TPUs\n",
        "|--------------------|-------|-------|\n",
        "| EfficientDet-Lite0 | 1     | 1     |\n",
        "| EfficientDet-Lite1 | 1     | 1     |\n",
        "| EfficientDet-Lite2 | 1     | 2     |\n",
        "| EfficientDet-Lite3 | 2     | 2     |\n",
        "| EfficientDet-Lite4 | 2     | 3     |\n",
        "\n",
        "If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LZdonJGCqieU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2515274-1209-4064-ab3f-04137a41c297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Searching for valid delegate with step 1\n",
            "Try to compile segment with 267 ops\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 3650 ms.\n",
            "\n",
            "Input model: smrc_model.tflite\n",
            "Input size: 4.24MiB\n",
            "Output model: smrc_model_edgetpu.tflite\n",
            "Output size: 5.57MiB\n",
            "On-chip memory used for caching model parameters: 4.21MiB\n",
            "On-chip memory remaining for caching model parameters: 3.29MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 267\n",
            "Operation log: smrc_model_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 264\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "NUMBER_OF_TPUS =  1\n",
        "\n",
        "!edgetpu_compiler --min_runtime_version 13 $TFLITE_FILENAME -d --num_segments=$NUMBER_OF_TPUS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2CjkduY02DF"
      },
      "source": [
        "**Beware when using multiple segments:** The Edge TPU Comiler divides the model such that all segments have roughly equal amounts of parameter data, but that does not mean all segments have the same latency. Especially when dividing an SSD model such as EfficientDet, this results in a latency-imbalance between segments, because SSD models have a large post-processing op that actually executes on the CPU, not on the Edge TPU. So although segmenting your model this way is better than running the whole model on just one Edge TPU, we recommend that you segment the EfficientDet-Lite model using our [profiling-based partitioner tool](https://github.com/google-coral/libcoral/tree/master/coral/tools/partitioner#profiling-based-partitioner-for-the-edge-tpu-compiler), which measures each segment's latency on the Edge TPU and then iteratively adjusts the segmentation sizes to provide balanced latency between all segments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyBBvyqx0XRn"
      },
      "source": [
        "## Download the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M43URVgg0ZcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "74c991ff-b7f3-4c1f-87ec-e6bc572877fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_78499beb-339d-4a62-b46c-a9575a4e5125\", \"smrc_model_edgetpu.tflite\", 5842624)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0184ff4b-61bf-48cf-b098-71f239de66eb\", \"railwayLabels.txt\", 21)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "#Download model and label file for edge TPU (Coral USB Accelerator)\n",
        "files.download(TFLITE_FILENAME.replace('.tflite', '_edgetpu.tflite'))\n",
        "files.download(LABELS_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS4u77W5gnzQ"
      },
      "source": [
        "## More resources\n",
        "\n",
        "* For more information about the Model Maker library used in this tutorial, see the [TensorFlow Lite Model Maker guide](https://www.tensorflow.org/lite/guide/model_maker) and [API reference](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker).\n",
        "\n",
        "* For other transfer learning tutorials that are compatible with the Edge TPU, see the [Colab tutorials for Coral](https://github.com/google-coral/tutorials#colab-tutorials-for-coral).\n",
        "\n",
        "* You can also find more examples that show how to run inference on the Edge TPU at [coral.ai/examples](https://coral.ai/examples/#code-examples/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "trainSMRC",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}